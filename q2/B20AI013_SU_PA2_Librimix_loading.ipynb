{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eS03dFU0DGH"
      },
      "outputs": [],
      "source": [
        "import pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgO_kPIXPKeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8b7f54-eb0e-434e-b77c-1f13b9e20c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install datasets -q --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5npbbuppKVpG"
      },
      "source": [
        "# Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SIK9VV5KRO8"
      },
      "source": [
        "## Downloading datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI0xIty8Ksir"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/datasets\n",
        "!mkdir /content/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCcu9OFaKaOZ"
      },
      "source": [
        "### VoxCeleb1-H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPGTIJy6zaZ0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import datasets\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6fLCZxezOY7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "861b69e6257b4119b7de7b262584da8f",
            "2b9026959ddf4b13a0674998ad26bf6f",
            "424e272be6af45cc8fa31655556a9418",
            "1b6063fd7b0540c99d303af99c99a853",
            "012fd377edca48cabd15574498826415"
          ]
        },
        "outputId": "9b5313ee-5e61-474c-b9c8-6d8a70b6ca8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "861b69e6257b4119b7de7b262584da8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/441M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b9026959ddf4b13a0674998ad26bf6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/412M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "424e272be6af45cc8fa31655556a9418"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/435M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b6063fd7b0540c99d303af99c99a853"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4874 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "012fd377edca48cabd15574498826415"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"Codec-SUPERB/Voxceleb1_test_original\")[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show fairseq"
      ],
      "metadata": {
        "id": "w8_Q6NzIru11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI2CrxlZnyrC"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "\n",
        "index_to_filepath_mapping = {}\n",
        "filepath_to_index_mapping = {}\n",
        "for i in range(len(dataset)):\n",
        "  sample = dataset[i]\n",
        "  sample_id = sample['id']\n",
        "  folder_id, yt_id, file_id = sample_id.split('+')\n",
        "  filepath = sample_id.replace('+', '/')\n",
        "  index_to_filepath_mapping[i] = filepath\n",
        "  filepath_to_index_mapping[filepath] = i\n",
        "\n",
        "assert len(filepath_to_index_mapping) == len(index_to_filepath_mapping), \"error here!\"\n",
        "dataset.index_to_filepath = index_to_filepath_mapping\n",
        "dataset.filepath_to_index = filepath_to_index_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVn7yvEn5uSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1831eb5-ca25-4a66-b986-ea218c7ca655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-02 14:35:25--  https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard.txt\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34257232 (33M) [text/plain]\n",
            "Saving to: ‘/content/datasets/voxceleb1h/list_test_hard.txt’\n",
            "\n",
            "/content/datasets/v 100%[===================>]  32.67M  7.69MB/s    in 4.2s    \n",
            "\n",
            "2024-04-02 14:35:31 (7.69 MB/s) - ‘/content/datasets/voxceleb1h/list_test_hard.txt’ saved [34257232/34257232]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/datasets/voxceleb1h\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard.txt -O /content/datasets/voxceleb1h/list_test_hard.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SGq9JxM6LYe"
      },
      "outputs": [],
      "source": [
        "with open('/content/datasets/voxceleb1h/list_test_hard.txt', 'r') as f:\n",
        "  list_test_hard = [line.strip('\\n') for line in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Zz6ePZb9aXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e87d7d0-8845-4aa4-db85-e09554b602ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4874/4874 [00:14<00:00, 344.41it/s]\n",
            "100%|██████████| 552536/552536 [00:00<00:00, 1377280.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset loaded\n",
            "9389\n",
            "bruh2\n",
            "(1, tensor([0.0068, 0.0064, 0.0049,  ..., 0.0000, 0.0000, 0.0000]), tensor([0.0009, 0.0030, 0.0008,  ..., 0.0000, 0.0000, 0.0000]))\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import Dataset, Audio\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "class VoxDatasetTest(Dataset):\n",
        "  def __init__(self, dataset, list_test_hard):\n",
        "    self.dataset = dataset\n",
        "    self.audios = []\n",
        "    self.padding_fn = []\n",
        "    padding_value = 0.0\n",
        "    self.maxlen = 0\n",
        "    for i in tqdm(range(len(dataset))):\n",
        "      sample = dataset[i]\n",
        "      self.audios.append(sample)\n",
        "      self.maxlen = max(self.maxlen, len(sample['audio']['array']))\n",
        "      self.padding_fn.append(\n",
        "          torch.nn.ConstantPad1d((0, self.maxlen - len(sample['audio']['array'])), padding_value)\n",
        "      )\n",
        "    self.list_test_hard = list_test_hard\n",
        "\n",
        "\n",
        "    sampling_rate = 16000\n",
        "    self.list_audio1 = []\n",
        "    self.list_audio2 = []\n",
        "    self.list_speaker_matches = []\n",
        "    self.padding_fns = []\n",
        "    for line in tqdm(self.list_test_hard):\n",
        "      a, b, c = line.split()\n",
        "      if b not in dataset.filepath_to_index or c not in dataset.filepath_to_index:\n",
        "        continue\n",
        "\n",
        "      a = int(a)\n",
        "      d, e = self.padding_fn[dataset.filepath_to_index[b]], self.padding_fn[dataset.filepath_to_index[c]]\n",
        "      b, c = self.audios[dataset.filepath_to_index[b]]['audio']['array'], self.audios[dataset.filepath_to_index[c]]['audio']['array']\n",
        "\n",
        "\n",
        "      self.list_speaker_matches.append(a)\n",
        "      self.list_audio1.append(b)\n",
        "      self.list_audio2.append(c)\n",
        "      self.padding_fns.append([d, e])\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.list_audio1)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if type(idx) == type(1):\n",
        "      a, b, c = self.list_speaker_matches[idx], self.list_audio1[idx], self.list_audio2[idx]\n",
        "      d, e = self.padding_fns[idx]\n",
        "      print('bruh2')\n",
        "      b = d(torch.Tensor(b))\n",
        "      c = e(torch.Tensor(c))\n",
        "      return a, b, c\n",
        "    else:\n",
        "      batch = []\n",
        "      for id in idx:\n",
        "        print('okay')\n",
        "        batch.append(self.__getitem__(id))\n",
        "      return batch\n",
        "\n",
        "voxdataset = VoxDatasetTest(dataset, list_test_hard)\n",
        "print('dataset loaded')\n",
        "print(len(voxdataset))\n",
        "sample = voxdataset[0]\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1F5K2h4I-W5",
        "outputId": "54c3d658-6250-4d13-c867-e87bf71ef986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n",
            "okay\n",
            "bruh2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not tuple",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d1db3ee716e6>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio1s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio2s\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvoxdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'something'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2813\u001b[0m         \u001b[0;34m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2815\u001b[0;31m         \u001b[0mn_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2816\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "def voxcollate(batch):\n",
        "  print('inside collate')\n",
        "  targets = torch.Tensor([sample[0] for sample in batch]).long()\n",
        "  audio1s = torch.Tensor([sample[1] for sample in batch])\n",
        "  audio2s = torch.Tensor([sample[2] for sample in batch])\n",
        "  return targets, audio1s, audio2s\n",
        "\n",
        "\n",
        "\n",
        "voxdataloader = DataLoader(voxdataset, batch_size = batch_size)\n",
        "\n",
        "try:\n",
        "  for targets, audio1s, audio2s in voxdataloader:\n",
        "    print('something')\n",
        "    break\n",
        "  print(targets.shape)\n",
        "  print(audio1s.shape)\n",
        "  print(audio2s.shape)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OEEhONNI0BG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from types import SimpleNamespace\n",
        "from transformers import AutoConfig, AutoModel\n",
        "\n",
        "\n",
        "\n",
        "wav2vec2_xlsr = SimpleNamespace(**{})\n",
        "wav2vec2_xlsr.model_tag = 'facebook/wav2vec2-large-xlsr-53'\n",
        "wav2vec2_xlsr.autoconfig = AutoConfig.from_pretrained(wav2vec2_xlsr.model_tag)\n",
        "wav2vec2_xlsr.automodel = AutoModel.from_config(wav2vec2_xlsr.autoconfig)\n",
        "wav2vec2_xlsr.automodel.eval()\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfJfiKbEIO_d"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypHBHJRDCwWd",
        "outputId": "6495d6ae-6ec2-48f2-fe4f-6bd43270d878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id10270/5r0dWxy17C8/00001.wav\n"
          ]
        }
      ],
      "source": [
        "print(list(dataset.filepath_to_index.keys())[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edNGv7_GKdub"
      },
      "source": [
        "### Kathbath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N14v_jR2yhHa"
      },
      "outputs": [],
      "source": [
        "!wget -c --tries=0 --read-timeout=20 https://my-bucket-a8b4b49c25c811ee9a7e8bba05fa24c7.s3.amazonaws.com/wham_noise.zip -P datasets/librispeech/LibriMix/storage_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PYNCEb4yxpV"
      },
      "outputs": [],
      "source": [
        "!mv datasets/librispeech/LibriMix/storage_dir/wham_noise.zip /content/wham_noise.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBADkH-IzbQc"
      },
      "outputs": [],
      "source": [
        "!unzip -l /content/wham_noise.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqh5ejj6VpWy"
      },
      "outputs": [],
      "source": [
        "!unzip wham_noise.zip \"wham_noise/tt/*\" -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awNi8Yq7WY6K"
      },
      "outputs": [],
      "source": [
        "!du -sh /content/wham_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm6gTXGIWpHs"
      },
      "outputs": [],
      "source": [
        "# !zip -r /content/tt.zip /content/wham_noise/tt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2zfZUdsxk-s"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_3LL281wmja"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#####################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NysIqdIa__HE"
      },
      "outputs": [],
      "source": [
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us_uALfR_iSl"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "tt_dir  = '/content/wham_noise/tt'\n",
        "\n",
        "max_duration = 0\n",
        "for path in tqdm(os.listdir(tt_dir)):\n",
        "  path = os.path.join(tt_dir, path)\n",
        "  duration = librosa.get_duration(filename=path)\n",
        "  max_duration = max(max_duration, duration)\n",
        "\n",
        "sample_filename = os.path.join(tt_dir, os.listdir(tt_dir)[0])\n",
        "print(f'max duration in test-clean:  {max_duration}')\n",
        "display.Audio(sample_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqtKy_ma-1RU"
      },
      "outputs": [],
      "source": [
        "\n",
        "from datasets import Dataset, Audio\n",
        "import math\n",
        "\n",
        "def load_audio_dataset(list_paths):\n",
        "  audio_dataset = Dataset.from_dict(\n",
        "    {\n",
        "        \"audio\": list_paths\n",
        "    }\n",
        "  ).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "  return audio_dataset\n",
        "\n",
        "\n",
        "import os\n",
        "tt_dir= '/content/wham_noise/tt'\n",
        "list_audio_paths = [os.path.join(tt_dir, path) for path in os.listdir(tt_dir) if path.endswith('.wav')][:2]\n",
        "audio_dataset = load_audio_dataset(list_audio_paths)\n",
        "\n",
        "print(audio_dataset[0]['audio']['array'].shape, audio_dataset[1]['audio']['array'].shape)\n",
        "\n",
        "padding_value = 0.0\n",
        "# max_len = max([len(audio_dataset[i]['audio']['array']) for i in range(len(audio_dataset))])\n",
        "max_len = 16000 * math.ceil(max_duration)\n",
        "\n",
        "padding_fn = [torch.nn.ConstantPad1d(\n",
        "    (0, max_len - len(audio_dataset[i]['audio']['array'])), padding_value) for i in range(len(audio_dataset))]\n",
        "audio_batch = torch.cat([\n",
        "    padding_fn[i](\n",
        "        torch.Tensor(audio_dataset[i]['audio']['array']).reshape(1, -1)\n",
        "    )\n",
        "    for i in range(len(audio_dataset))])\n",
        "\n",
        "batch_output = wav2vec2_xlsr.automodel.feature_extractor(audio_batch)\n",
        "batch_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0nG42en01dC"
      },
      "outputs": [],
      "source": [
        "wav2vec2_xlsr.autoconfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TS1hjOxy3A5"
      },
      "outputs": [],
      "source": [
        "type(audio_dataset[0]['audio']['array'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07uGjB-Ny5sE"
      },
      "outputs": [],
      "source": [
        "sample = torch.Tensor(audio_dataset[0]['audio']['array']).reshape(1, -1)\n",
        "test_output = wav2vec2_xlsr.automodel.feature_extractor(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsB6blVX4xZS"
      },
      "outputs": [],
      "source": [
        "for i in range(len(audio_dataset)):\n",
        "  print(\n",
        "      np.mean(np.abs(audio_dataset[i]['audio']['array'])) \\\n",
        "      / np.mean(audio_dataset[i]['audio']['array'])\n",
        "  )\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB6VJl3-zMPg"
      },
      "outputs": [],
      "source": [
        "type(test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RPA_N0OzOzp"
      },
      "outputs": [],
      "source": [
        "test_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhDUresiwEWe"
      },
      "outputs": [],
      "source": [
        "wav2vec2_xlsr.autoconfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjUlDbuhkxjH"
      },
      "outputs": [],
      "source": [
        "wav2vec2_xlsr.automodel.feature_extractor.forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-giXjUKjB7u"
      },
      "outputs": [],
      "source": [
        "wav2vec2_xlsr.automodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1naaaqGsrfPT"
      },
      "outputs": [],
      "source": [
        "!zip /content/tt.zip --out /content/new_tt.zip -s 100m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V_086jnrxu_"
      },
      "outputs": [],
      "source": [
        "files.download('new_tt.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErvBBm-Kr77C"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 20):\n",
        "  numeral = f'0{i}'[-2:]\n",
        "  path = f'new_tt.z{numeral}'\n",
        "  if os.path.exists(path):\n",
        "    files.download(path)\n",
        "  else:\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7HwwneEXM0z"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/tt.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k5qO9eCfma3"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/JorisCos/LibriMix.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckp0pcXKfp_m"
      },
      "outputs": [],
      "source": [
        "%cd LibriMix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1_Y1DwkfvdF"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpPGpYt1fyUL"
      },
      "outputs": [],
      "source": [
        "# !cat README.md\n",
        "# import os\n",
        "!bash generate_librimix.sh storage_dir"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}